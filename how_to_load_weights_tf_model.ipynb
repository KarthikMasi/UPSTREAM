{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "import numpy as np \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilities -- needed for model, specified for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(truth, pred, smooth=1):\n",
    "    \n",
    "    true_flat = tf.reshape(truth, [-1])\n",
    "    pred_flat = tf.reshape(pred, [-1])\n",
    "    \n",
    "    intersection = tf.reduce_sum(true_flat*pred_flat)\n",
    "    return ((2. * intersection)+smooth) / (tf.reduce_sum(true_flat)+tf.reduce_sum(pred_flat) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(gt, pred):\n",
    "    return 1-dice_coef(gt, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic unet code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrink the size of the convolution layers\n",
    "shrink = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (240,240,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512/shrink, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256/shrink, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128/shrink, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64/shrink, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64/shrink, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs, conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss =dice_coef_loss, metrics = [dice_coef])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load weights from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"extra_stuff/weights00000200.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get all weights for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get weights for a single layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input layer has no weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get weights for the 1st conv layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example conv layer\n",
    "- weights come in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.1152328 ,  0.5276617 , -0.7377614 , -0.52538556,\n",
       "            0.45505467,  0.7270211 , -0.38682103, -0.00731626]],\n",
       " \n",
       "         [[-0.568643  ,  0.2057117 ,  0.15583187, -0.38538706,\n",
       "            0.17416316,  0.8215804 , -0.16912712, -0.20825058]],\n",
       " \n",
       "         [[ 0.2531662 ,  0.27577066, -0.408096  , -0.08812112,\n",
       "            0.12006578,  0.10969435,  0.23568417, -0.05589726]]],\n",
       " \n",
       " \n",
       "        [[[-0.4871996 , -0.09196077, -0.4233251 ,  0.16528891,\n",
       "            0.27917728,  0.9409635 ,  0.29363814,  0.8791226 ]],\n",
       " \n",
       "         [[ 0.53708804, -0.36101764,  0.40414205, -0.1210577 ,\n",
       "            0.45317525, -0.22057651,  0.6186366 , -0.11786763]],\n",
       " \n",
       "         [[-0.1941728 , -0.2505122 ,  0.6309221 , -0.00540727,\n",
       "           -0.5391329 ,  0.56538314, -0.7884627 ,  0.17512968]]],\n",
       " \n",
       " \n",
       "        [[[ 0.52644366,  0.42978835,  0.0324479 ,  0.53517   ,\n",
       "            0.20992978, -1.0285648 , -0.99992865,  0.10883015]],\n",
       " \n",
       "         [[ 0.23594022, -0.34976366, -0.0488033 ,  0.6410055 ,\n",
       "            0.2480007 ,  0.6342566 , -0.47426438,  0.04443003]],\n",
       " \n",
       "         [[-0.26173243, -0.12921804, -0.6682624 , -0.22572753,\n",
       "           -0.58298403,  0.1403366 ,  0.6996737 ,  0.3007192 ]]]],\n",
       "       dtype=float32),\n",
       " array([-0.0031771 ,  0.00470462, -0.00069402,  0.00111731, -0.00703088,\n",
       "        -0.01144939,  0.00474645, -0.00904452], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 element list\n",
    "- let's look through these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( model.layers[1].get_weights() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0th idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3x3 kernel size for the 64/shrink=8 filters in the first conv layer. and the 1 corresponds to 1 channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1, 8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 8 biases for the 8 filters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
